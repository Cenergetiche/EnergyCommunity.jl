{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"C:/Users/Davide/git/gitdf/EnergyCommunity.jl/run_cloud/results_paper_ANC\" #git/gitdf/EnergyCommunity.jl/run_cloud\"\n",
    "saveiter_dir = \"$parent_dir/iter\"\n",
    "saveenum_dir = \"$parent_dir/enum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using EnergyCommunity\n",
    "using FileIO\n",
    "using HiGHS, Plots\n",
    "using JuMP\n",
    "using Gurobi\n",
    "using Games\n",
    "using TickTock\n",
    "using Combinatorics\n",
    "using DataFrames\n",
    "using JLD2\n",
    "using Latexify, LaTeXStrings\n",
    "using YAML\n",
    "using CSV\n",
    "using Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ENUM_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_size_list_enum = []\n",
    "dict_enums = Dict()\n",
    "\n",
    "for filename in readdir(saveenum_dir)\n",
    "    if endswith(filename, \".jld2\") && startswith(filename, \"enum_simulations_results_\")\n",
    "        size_enum = parse(Int, replace(filename, \"enum_simulations_results_\"=>\"\", \".jld2\"=>\"\"))\n",
    "        push!(EC_size_list_enum, size_enum)\n",
    "        dict_enums[size_enum] = load(\"$saveenum_dir/enum_simulations_results_$size_enum.jld2\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENUM_MODE: Create reward redistribution of enum modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward_enum = DataFrame()\n",
    "\n",
    "for EC_size in EC_size_list_enum\n",
    "    df_reward_temp = deepcopy(dict_enums[EC_size][\"df_reward_enum\"])\n",
    "    df_reward_temp[!, \"EC_size\"] .= EC_size\n",
    "\n",
    "    # Put users as columns\n",
    "    df_reward_temp = unstack(stack(df_reward_temp), :user_set, :value)\n",
    "    if nrow(df_reward_enum) == 0\n",
    "        df_reward_enum = df_reward_temp\n",
    "    else\n",
    "        df_reward_enum = vcat(df_reward_enum, df_reward_temp, cols=:union)\n",
    "    end\n",
    "end\n",
    "\n",
    "# sort by user set\n",
    "df_reward_enum = df_reward_enum[!, [\"variable\"; \"EC_size\"; EC_CODE; [\"user$i\" for i = 1:(ncol(df_reward_enum)-3)]]]\n",
    "\n",
    "df_reward_enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENUM_MODE: Create comparison of computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_df_time = [\"EC_size\"]#, \"title\"]\n",
    "\n",
    "df_time_enum = DataFrame()\n",
    "\n",
    "for EC_size in EC_size_list_enum\n",
    "    df_time_temp = DataFrame(dict_enums[EC_size][\"df_time_enum\"])  # dict_time_enum\n",
    "\n",
    "    df_time_temp[!, setdiff(names(df_time_temp), [\"name\", \"id_run\", \"EC_size\"])] ./= 3600  # change units to hours\n",
    "\n",
    "    # df_time_temp[!, \"title\"] = [L\"Time [h]\"]\n",
    "    df_time_temp = df_time_temp[!, [header_df_time; setdiff(names(df_time_temp), header_df_time)]]\n",
    "\n",
    "    if nrow(df_time_enum) == 0\n",
    "        df_time_enum = df_time_temp\n",
    "    else\n",
    "        df_time_enum = vcat(df_time_enum, df_time_temp)\n",
    "    end\n",
    "end\n",
    "\n",
    "df_time_enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ITER_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run_simulations_iter = CSV.read(\"$saveiter_dir/options_backup.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_iter = Dict()\n",
    "n_iter = 0\n",
    "\n",
    "while isfile(\"$saveiter_dir/iter_simulations_results_$(n_iter+1).jld2\")\n",
    "    n_iter += 1\n",
    "    dict_iter[n_iter] = load(\"$saveiter_dir/iter_simulations_results_$n_iter.jld2\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ITER_MODE: Comparison of reward distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward_iter = DataFrame()\n",
    "\n",
    "largest_user_set = []\n",
    "\n",
    "for id_run in 1:n_iter\n",
    "    df_reward_temp = deepcopy(dict_iter[id_run][\"df_reward_iter\"])\n",
    "    df_reward_temp[!, \"EC_size\"] .= nrow(df_reward_temp)-1\n",
    "    df_reward_temp[!, \"id_run\"] .= id_run\n",
    "\n",
    "    # Put users as columns\n",
    "    df_reward_temp = unstack(stack(df_reward_temp), :user_set, :value)\n",
    "    if nrow(df_reward_iter) == 0\n",
    "        df_reward_iter = df_reward_temp\n",
    "    else\n",
    "        df_reward_iter = vcat(df_reward_iter, df_reward_temp, cols=:union)\n",
    "    end\n",
    "end\n",
    "\n",
    "# sort by user set\n",
    "df_reward_iter = df_reward_iter[!, [\"variable\"; \"EC_size\"; \"id_run\"; EC_CODE; [\"user$i\" for i = 1:(ncol(df_reward_iter)-4)]]]\n",
    "# CSV.write(\"reward_iter.csv\", df_reward_iter)\n",
    "first(df_reward_iter, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ITER_MODE: Create comparison of computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_iter = DataFrame()\n",
    "\n",
    "for id_run in 1:n_iter\n",
    "    df_time_temp = deepcopy(dict_iter[id_run][\"df_time_iter\"])\n",
    "\n",
    "    df_time_temp[!, 3:end] ./= 3600  # change units to hours\n",
    "    \n",
    "    df_time_temp[!, \"id_run\"] .= id_run\n",
    "\n",
    "    if nrow(df_time_iter) == 0\n",
    "        df_time_iter = df_time_temp\n",
    "    else\n",
    "        df_time_iter = vcat(df_time_iter, df_time_temp)\n",
    "    end\n",
    "end\n",
    "\n",
    "header_cols = [\"name\", \"id_run\", names(df_run_simulations_iter)...]\n",
    "df_list_rewards = setdiff(names(df_time_iter), intersect(header_cols, names(df_run_simulations_iter)))\n",
    "\n",
    "df_time_iter = hcat(df_run_simulations_iter[df_time_iter[!, \"id_run\"], :], df_time_iter[!, df_list_rewards])\n",
    "df_time_iter = df_time_iter[!, [header_cols; setdiff(names(df_time_iter), header_cols)]]\n",
    "\n",
    "# CSV.write(\"comp_time_iter.csv\", df_time_iter)\n",
    "\n",
    "df_time_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ITER_MODE: Create comparison of time per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history_iter = DataFrame()\n",
    "\n",
    "for id_run in 1:n_iter\n",
    "    df_history_temp = deepcopy(dict_iter[id_run][\"df_history\"])\n",
    "    df_history_temp[!, \"id_run\"] .= id_run\n",
    "\n",
    "    df_history_temp = df_history_temp[!, [\"id_run\"; setdiff(names(df_history_temp), [\"id_run\"])]]\n",
    "\n",
    "    if nrow(df_history_iter) == 0\n",
    "        df_history_iter = df_history_temp\n",
    "    else\n",
    "        df_history_iter = vcat(df_history_iter, df_history_temp)\n",
    "    end\n",
    "end\n",
    "header_cols = [\"name\", \"id_run\"]\n",
    "df_history_iter = df_history_iter[!, [header_cols; setdiff(names(df_history_iter), header_cols)]]\n",
    "\n",
    "CSV.write(\"$parent_dir/raw_history.csv\", df_history_iter)\n",
    "\n",
    "first(df_history_iter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elapsed time to history dataframe\n",
    "\n",
    "sort!(df_history_iter, [:id_run, :name])\n",
    "\n",
    "df_history_iter[!, :iteration_time] .= NaN\n",
    "\n",
    "groups = groupby(df_history_iter, [:id_run, :name])\n",
    "\n",
    "for (grp_key, grp) in zip(keys(groups), groups)\n",
    "    grp[!, :iteration_time] = [grp[1, :elapsed_time]; diff(grp[!, :elapsed_time])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_iterations = @pipe df_history_iter |> groupby(_, [:name, :id_run]) |>\n",
    "    combine(_, \n",
    "        :iteration => maximum => :max_iter,\n",
    "        :elapsed_time => first => :initialization_time,\n",
    "        :elapsed_time => maximum => :elapsed_time,\n",
    "        :elapsed_time => (x -> maximum(x)/(length(x)-1)) => :mean_time,\n",
    "        :iteration_time => maximum => :max_duration_iter,\n",
    "        :iteration_time => (x -> sum(x .> 3 * 3600)) => :iteration_time_beyond_3h,\n",
    "        )\n",
    "\n",
    "first(df_summary_iterations, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((k,), v) in pairs(groupby(df_history_iter, [:name]))\n",
    "    # initialize plot\n",
    "    p = plot(title=k)\n",
    "\n",
    "    # loop over run ids\n",
    "    for ((k_r,), v_r) in pairs(groupby(v, [:id_run]))\n",
    "        plot!(v_r[!, :iteration], v_r[!, :elapsed_time], label=\"id_run: $k_r\")\n",
    "    end\n",
    "\n",
    "    xlabel!(\"Iteration [#]\")\n",
    "    ylabel!(\"Elapsed time [s]\")\n",
    "\n",
    "    display(p)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ITER_MODE: Comparison of iteration time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((k,), v) in pairs(groupby(df_history_iter, [:name]))\n",
    "    # initialize plot\n",
    "    p = plot(title=k)\n",
    "\n",
    "    # loop over run ids\n",
    "    for ((k_r,), v_r) in pairs(groupby(v, [:id_run]))\n",
    "        delta_time = [v_r[1, :elapsed_time]; v_r[2:end, :elapsed_time] .- v_r[1:end-1, :elapsed_time]]\n",
    "        plot!(v_r[!, :iteration], delta_time, label=\"id_run: $k_r\")\n",
    "    end\n",
    "\n",
    "    xlabel!(\"Iteration [#]\")\n",
    "    ylabel!(\"Elapsed time [s]\")\n",
    "\n",
    "    display(p)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ITER_MODE: Comparison of upper and lower bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_plot = 3\n",
    "\n",
    "for ((k,), v) in pairs(groupby(df_history_iter, [:name]))\n",
    "    # initialize plot\n",
    "    # loop over run ids\n",
    "    for ((k_r,), v_r) in pairs(groupby(v, [:id_run]))\n",
    "        p = plot(v_r[!, :iteration], v_r[!, :value_min_surplus], label=\"Upper bound\", color=\"red\", title=\"$k - id_run: $k_r\")\n",
    "        plot!(v_r[!, :iteration], v_r[!, :lower_problem_min_surplus], label=\"Lower bound\", color=\"blue\")\n",
    "\n",
    "        best_obj = minimum(v_r[!, :value_min_surplus])\n",
    "\n",
    "        xlabel!(\"Iteration [#]\")\n",
    "        ylabel!(\"Obj. value\")\n",
    "        # ylims!(p, -rng_plot*best_obj, rng_plot*best_obj)\n",
    "    \n",
    "        display(p)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL: Merge all data into final files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reward outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_df_reward = [\"EC_size\", \"id_run\", \"variable\"]\n",
    "\n",
    "# create backup copies of dictionaries\n",
    "df_reward_enum_copy = deepcopy(df_reward_enum)\n",
    "df_reward_iter_copy = deepcopy(df_reward_iter)\n",
    "\n",
    "# clean dataframes enum\n",
    "df_reward_enum_copy[!, \"name\"] .= \"enum\"\n",
    "df_reward_enum_copy[!, \"id_run\"] .= \"-\"\n",
    "df_reward_enum_copy[!, \"variable\"] .= replace.(df_reward_enum_copy[!, \"variable\"], \"_enum\"=>\"\")\n",
    "\n",
    "# clean dataframes iter\n",
    "df_reward_iter_copy[!, \"name\"] .= \"iter\"\n",
    "df_reward_iter_copy[!, \"id_run\"] = string.(df_reward_iter_copy[!, \"id_run\"])\n",
    "df_reward_iter_copy[!, \"variable\"] .= replace.(df_reward_iter_copy[!, \"variable\"], \"_iter\"=>\"\")\n",
    "\n",
    "# merge dataframes\n",
    "df_reward_all = vcat(df_reward_enum_copy, df_reward_iter_copy, cols=:union)\n",
    "df_reward_all = df_reward_all[!, [header_df_reward; setdiff(names(df_reward_iter), header_df_reward)]]\n",
    "\n",
    "CSV.write(\"$parent_dir/reward.csv\", df_reward_all)\n",
    "\n",
    "first(df_reward_all, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_df_time = [\"EC_size\", \"id_run\"]\n",
    "\n",
    "# work on copies of dataframes\n",
    "df_time_enum_copy = df_time_enum[:, setdiff(names(df_time_enum), [\"title\", \"id_run\"])]\n",
    "df_time_iter_copy = deepcopy(df_time_iter)\n",
    "\n",
    "# clean dataframe enum\n",
    "rename!(df_time_enum_copy, replace.(names(df_time_enum_copy), \"_enum\"=>\"\"))\n",
    "# rename!(df_time_enum_copy, :mode_time=>:mode)\n",
    "df_time_enum_copy[!, \"name\"] = replace.(df_time_enum_copy[!, \"name\"], \"_mode\"=>\"\")\n",
    "\n",
    "# clean dataframe iter\n",
    "df_time_iter_copy[!, \"name\"] .= \"iter\"\n",
    "rename!(df_time_iter_copy, replace.(names(df_time_iter_copy), \"_iter\"=>\"\"))\n",
    "\n",
    "# merge dataframes\n",
    "\n",
    "df_time_all = vcat(df_time_enum_copy, df_time_iter_copy, cols=:union)\n",
    "df_time_all = df_time_all[!, [header_df_time; setdiff(names(df_time_all), header_df_time)]]\n",
    "\n",
    "CSV.write(\"$parent_dir/comp_time.csv\", df_time_all)\n",
    "\n",
    "df_time_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run_simulations_iter_copy[!, :id_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_iterations_copy = deepcopy(df_summary_iterations)\n",
    "df_summary_iterations_copy[!, \"name\"] = replace.(df_summary_iterations_copy[!, \"name\"], \"_iter\"=>\"\")\n",
    "\n",
    "df_run_simulations_iter_copy = deepcopy(df_run_simulations_iter)\n",
    "df_run_simulations_iter_copy[!, :id_run] = 1:nrow(df_run_simulations_iter_copy)\n",
    "\n",
    "df_summary_iterations_merged = leftjoin(df_summary_iterations_copy, df_run_simulations_iter_copy, on=[:id_run])\n",
    "\n",
    "df_summary_iterations_merged = df_summary_iterations_merged[\n",
    "    !, \n",
    "    [\n",
    "        names(df_summary_iterations_copy);\n",
    "        setdiff(names(df_summary_iterations_merged), names(df_summary_iterations_copy))\n",
    "    ]\n",
    "]\n",
    "\n",
    "CSV.write(\"$parent_dir/summary_iterations.csv\", df_summary_iterations_merged)\n",
    "\n",
    "df_summary_iterations_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bfaeecedf253908c6d8da07a77979cd04405f6ff56d07cd432c822e25783765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
